{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd0f14d0265c58dcca937431964c116f2c2daf05ac4f2d61c58d7f022c31778fcd5",
   "display_name": "Python 3.6.13 64-bit ('torch': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f14d0265c58dcca937431964c116f2c2daf05ac4f2d61c58d7f022c31778fcd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1 Model Construction\n",
    "## 1.1 Module class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(256, 10)\n",
    "    def forward(self, x):\n",
    "        a = self.act(self.hidden(x))\n",
    "        return self.output(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MLP(\n  (hidden): Linear(in_features=784, out_features=256, bias=True)\n  (act): ReLU()\n  (output): Linear(in_features=256, out_features=10, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "net = MLP()\n",
    "print(net)"
   ]
  },
  {
   "source": [
    "## 1.2 Implement a class that has the same function as the Sequential class "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    from collections import OrderedDict\n",
    "    def __init__(self, *args):\n",
    "        super(MySequential, self).__init__()\n",
    "        if len(args) == 1 and isinstance(args[0], OrderedDict):\n",
    "            for key, module in args[0].items():\n",
    "                self.add_module(key, module)\n",
    "        else:\n",
    "            # enumerate returns an iterable object with index starting from 0\n",
    "            for idx, module in enumerate(args):\n",
    "                self.add_module(str(idx), module)\n",
    "    def forward(self, x):\n",
    "        # self._modules returns an OrderedDict \n",
    "        # .values() returns the values from key-value pairs\n",
    "        for module in self._modules.values():\n",
    "            x = module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MySequential(\n  (0): Linear(in_features=784, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=10, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "net = MySequential(\n",
    "        nn.Linear(784, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 10)\n",
    ")\n",
    "print(net)\n"
   ]
  },
  {
   "source": [
    "## 1.3 Difference between `Sequential` and `ModuleList`\n",
    "`Sequential` and `ModuleList` both can be used to save a network consisted of multiple layers like a list. \n",
    "\n",
    "`Sequential` can be used to build a network sequentially and calculate the output according to the input. So the shape of output and input of adjacent layers must be Compatible. `forward()` is defined automatically.\n",
    "\n",
    "`ModuleList` can NOT be used to calculate the output. The aim of `ModuleList`is only to save a list of layers. We need to define `forward()` by ourselves."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ModuleList can act as an iterable, or be indexed using ints\n",
    "        for i, l in enumerate(self.linears):\n",
    "            x = self.linears[i // 2](x) + l(x)\n",
    "        return x"
   ]
  },
  {
   "source": [
    "## 1.4 `ModuleDict`\n",
    "We also need to define `forward()` by ourselves."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\nLinear(in_features=256, out_features=10, bias=True)\nModuleDict(\n  (act): ReLU()\n  (linear): Linear(in_features=784, out_features=256, bias=True)\n  (output): Linear(in_features=256, out_features=10, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "net = nn.ModuleDict({\n",
    "    \"linear\": nn.Linear(784, 256),\n",
    "    \"act\": nn.ReLU(),\n",
    "})\n",
    "net[\"output\"] = nn.Linear(256, 10)\n",
    "print(net.linear)\n",
    "print(net[\"output\"])\n",
    "print(net)"
   ]
  },
  {
   "source": [
    "# 2 Parameter Management"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n  (0): Linear(in_features=4, out_features=3, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=3, out_features=1, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 3), nn.ReLU(), nn.Linear(3, 1))  # pytorch已进行默认初始化\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "source": [
    "## 2.1 Parameter Access"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'generator'>\ntorch.Size([3, 4])\ntorch.Size([3])\ntorch.Size([1, 3])\ntorch.Size([1])\n\n0.weight torch.Size([3, 4])\n0.bias torch.Size([3])\n2.weight torch.Size([1, 3])\n2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Access to parameters of all layers\n",
    "print(type(net.named_parameters()))\n",
    "for param in net.parameters():\n",
    "    print(param.size())\n",
    "print()\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "weight torch.Size([3, 4]) <class 'torch.nn.parameter.Parameter'>\nbias torch.Size([3]) <class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "# Access to parameters of one specific layer\n",
    "for name, param in net[0].named_parameters():\n",
    "    print(name, param.size(), type(param))"
   ]
  },
  {
   "source": [
    "torch.nn.Paramter is a subclass of Tensor. All Parameter objects will be automatically saved into net.named_parmaters()\n",
    "\n",
    "## 2.2 Parameter Initialization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.weight tensor([[-0.0162, -0.0005, -0.0259, -0.0084],\n        [-0.0125, -0.0123,  0.0036,  0.0029],\n        [-0.0108, -0.0059,  0.0003,  0.0111]])\n0.bias tensor([0., 0., 0.])\n2.weight tensor([[ 0.0044, -0.0031,  0.0052]])\n2.bias tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        init.normal_(param, mean=0, std=0.01)\n",
    "        print(name, param.data)\n",
    "    if \"bias\" in name:\n",
    "        init.constant_(param, val=0)\n",
    "        print(name, param.data)"
   ]
  },
  {
   "source": [
    "## 2.3 Custom Initialization\n",
    "Note: Parameter initialization should NOT be tracked. 2 Methods:\n",
    "- `with torch.no_grad():`\n",
    "- using `param.data`\n",
    "### 2.3.1 Implement a custom `init.normal_`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_(tensor, mean=0, std=1):\n",
    "    with torch.no_grad():\n",
    "        return tensor.normal_(tensor, mean, std)"
   ]
  },
  {
   "source": [
    "### 2.3.2 Implement a custom probability distribution\n",
    "We have half the probability of initializing the weight to 0, and the other half of the probability of initializing the weight as uniformly distributed random numbers in the two intervals $[−10,−5]$ and $[5,10]$. \n",
    "\n",
    "And we set bias as 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.weight tensor([[ 0.0000, -0.0000, -5.5244,  0.0000],\n        [ 0.0000, -6.3243, -0.0000,  8.9183],\n        [ 0.0000,  0.0000,  0.0000, -6.6984]])\n2.weight tensor([[-5.9246,  0.0000,  7.7134]])\n"
     ]
    }
   ],
   "source": [
    "def init_weight_(tensor):\n",
    "    with torch.no_grad():\n",
    "        tensor.uniform_(-10, 10)\n",
    "        tensor *= (tensor.abs() >= 5).float()\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        init_weight_(param)\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.bias tensor([1., 1., 1.])\n2.bias tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if \"bias\" in name:\n",
    "        param.data += 1 \n",
    "        print(name, param.data)"
   ]
  },
  {
   "source": [
    "## 2.4 Tied Parameters\n",
    "Share parameters across multiple layers\n",
    "\n",
    "$h = w_1x,\\ y = w_2h = w_1w_2x , dy/dw_2 = h,\\ dh/dw_1 = x,\\ dy/dw_1 = w_2x = h$\n",
    "- Sharing Parameters: `net[0].weight.grad = h + h`\n",
    "- Not Sharing Parameters:  `net[0].weight.grad = h, net[1].weight.grad = h`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sequential(\n  (0): Linear(in_features=1, out_features=1, bias=False)\n  (1): Linear(in_features=1, out_features=1, bias=False)\n)\nSharing Parameters: \n0.weight tensor([[3.]])\nNot Sharing Parameters: \n0.weight tensor([[3.]])\n1.weight tensor([[3.]])\n"
     ]
    }
   ],
   "source": [
    "linear = nn.Linear(1, 1, bias=False)\n",
    "linear2 = nn.Linear(1, 1, bias=False)\n",
    "linear3 = nn.Linear(1, 1, bias=False)\n",
    "net_shared = nn.Sequential(linear, linear)\n",
    "net_unshared = nn.Sequential(linear2, linear3)\n",
    "print(net_shared)\n",
    "\n",
    "# network sharing parameters\n",
    "print(\"Sharing Parameters: \")\n",
    "for name, param in net_shared.named_parameters():\n",
    "    init.constant_(param, val=3)\n",
    "    print(name, param.data)\n",
    "    \n",
    "\n",
    "print(\"Not Sharing Parameters: \")\n",
    "# network not sharing parameters\n",
    "for name, param in net_unshared.named_parameters():\n",
    "    init.constant_(param, val=3)\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nFalse\nFalse\n"
     ]
    }
   ],
   "source": [
    "# The two layers are actually at the same position in memory\n",
    "print(id(net_shared[0]) == id(net_shared[1]))\n",
    "print(id(net_shared[0].weight) == id(net_shared[1].weight))\n",
    "\n",
    "print(id(net_unshared[0]) == id(net_unshared[1]))\n",
    "print(id(net_unshared[0].weight) == id(net_unshared[1].weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[6.]]) tensor([[6.]])\ntensor([[3.]]) tensor([[3.]])\n"
     ]
    }
   ],
   "source": [
    "# Also the backpropagation will be accumulated\n",
    "x1 = torch.ones((1, 1), requires_grad=True)\n",
    "x2 = torch.ones((1, 1), requires_grad=True)\n",
    "y_shared = net_shared(x1).sum()\n",
    "y_shared.backward()\n",
    "y_unshared = net_unshared(x2).sum()\n",
    "y_unshared.backward()\n",
    "\n",
    "print(net_shared[0].weight.grad, net_shared[1].weight.grad)\n",
    "print(net_unshared[0].weight.grad, net_unshared[1].weight.grad)"
   ]
  },
  {
   "source": [
    "# 3 Custom layers\n",
    "## 3.1 Layers without Parameters\n",
    "A layer that subtract the mean from the input"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CenteredLayer, self).__init__(**kwargs)\n",
    "    def forward(self, x):\n",
    "        return x - x.mean()\n",
    "\n",
    "layer = CenteredLayer()\n",
    "layer(torch.tensor([1,2,3,4,5], dtype=torch.float))"
   ]
  },
  {
   "source": [
    "## 3.2 Layers with Parameters\n",
    "We can use `ParameterList` and `ParameterDict` to define the parameters we need."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MyDense(\n  (params): ParameterList(\n      (0): Parameter containing: [torch.FloatTensor of size 4x4]\n      (1): Parameter containing: [torch.FloatTensor of size 4x4]\n      (2): Parameter containing: [torch.FloatTensor of size 4x4]\n      (3): Parameter containing: [torch.FloatTensor of size 4x1]\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "class MyDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDense, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(4, 4)) for i in range(3)])\n",
    "        self.params.append(nn.Parameter(torch.randn(4, 1)))\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.params)):\n",
    "            x = torch.mm(x, self.params[i])\n",
    "        return x\n",
    "\n",
    "net = MyDense()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MyDictDense(\n  (params): ParameterDict(\n      (0): Parameter containing: [torch.FloatTensor of size 4x4]\n      (1): Parameter containing: [torch.FloatTensor of size 4x4]\n      (2): Parameter containing: [torch.FloatTensor of size 4x4]\n      (3): Parameter containing: [torch.FloatTensor of size 4x1]\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "class MyDictDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDictDense, self).__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "            \"0\": nn.Parameter(torch.randn(4, 4)),\n",
    "            \"1\": nn.Parameter(torch.randn(4, 4)),\n",
    "            \"2\": nn.Parameter(torch.randn(4, 4))\n",
    "        })\n",
    "        self.params.update({\"3\": \n",
    "            nn.Parameter(torch.randn(4, 1))})\n",
    "    def forward(self, x):\n",
    "        for i in self.params.keys():\n",
    "            x = torch.mm(x, self.params[i])\n",
    "        return x\n",
    "\n",
    "net = MyDictDense()\n",
    "print(net)"
   ]
  },
  {
   "source": [
    "# 4 File I/O\n",
    "## 4.1 Read/Write Tensor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Write\n",
    "x = torch.ones(3)\n",
    "torch.save(x, \"./data/FileIO/x.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Read\n",
    "x2 = torch.load(\"./data/FileIO/x.pt\")\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([1., 1., 1.]), tensor([0., 0., 0., 0.])]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Save multiple tensors at the same time with list\n",
    "x  = torch.ones(3)\n",
    "y = torch.zeros(4)\n",
    "torch.save([x, y], \"./data/FileIO/xy.pt\")\n",
    "xy_list = torch.load(\"./data/FileIO/xy.pt\")\n",
    "xy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'x': tensor([1., 1., 1.]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Save multiple tensors at the same time with Dictionary\n",
    "torch.save({\"x\": x, \"y\": y}, \"./data/FileIO/xy_dict.pt\")\n",
    "xy = torch.load(\"./data/FileIO/xy_dict.pt\")\n",
    "xy"
   ]
  },
  {
   "source": [
    "## 4.2 Read/Write Model\n",
    "### 4.2.1 Transform\n",
    "`state_dict()` can be used to describe the **network** with a Dictionary with name of parameters as keys and data of parameters(Tensor) as values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('hidden.weight',\n",
       "              tensor([[1., 1., 1.],\n",
       "                      [1., 1., 1.]])),\n",
       "             ('hidden.bias', tensor([1., 1.])),\n",
       "             ('output.weight', tensor([[1., 1.]])),\n",
       "             ('output.bias', tensor([1.]))])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# transform the model with Dictionary\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden = nn.Linear(3, 2)\n",
    "        self.act = nn.ReLU()\n",
    "        self.output = nn.Linear(2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        a = self.act(self.hidden(x))\n",
    "        return self.output(a)\n",
    "net = MLP()\n",
    "for param in net.parameters():\n",
    "    torch.nn.init.constant_(param, val=1)\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.001,\n",
       "   'momentum': 0.9,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'params': [140621300908392,\n",
       "    140621300789536,\n",
       "    140621300910048,\n",
       "    140621300909976]}]}"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# transform the optimizer with Dictionary\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer.state_dict()"
   ]
  },
  {
   "source": [
    "### 4.2.2 Save and Load\n",
    "Two methods to save and load:\n",
    "- with `state_dict()`: \n",
    "    ```\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "    model = TheModelClass(*args, **kwargs)\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    ```\n",
    "- save directly\n",
    "    ```\n",
    "    torch.save(model, PATH)\n",
    "    model = torch.load(PATH)\n",
    "    ```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "torch.save(net.state_dict(), \"./data/FileIO/net.pt\")\n",
    "torch.save(optimizer, \"./data/FileIO/optim.pt\") #optimizer can not be loaded with `state_dict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[1., 1., 1.],\n        [1., 1., 1.]], requires_grad=True)\nParameter containing:\ntensor([1., 1.], requires_grad=True)\nParameter containing:\ntensor([[1., 1.]], requires_grad=True)\nParameter containing:\ntensor([1.], requires_grad=True)\nSGD (\nParameter Group 0\n    dampening: 0\n    lr: 0.001\n    momentum: 0.9\n    nesterov: False\n    weight_decay: 0\n)\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "net2 = MLP()\n",
    "net2.load_state_dict(torch.load(\"./data/FileIO/net.pt\"))\n",
    "\n",
    "optimizer2 = torch.load(\"./data/FileIO/optim.pt\")\n",
    "\n",
    "for param in net2.parameters():\n",
    "    print(param)\n",
    "\n",
    "print(optimizer2)"
   ]
  },
  {
   "source": [
    "# 5 Use GPU\n",
    "## 5.1 Device"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# check whether GPU is avaliable\n",
    "import torch\n",
    "from torch import nn\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# check how many GPU we have\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# check index of current GPU\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the name of our GPU with the index\n",
    "#torch.cuda.get_device_name(0)"
   ]
  },
  {
   "source": [
    "## 5.2 Tensor on GPU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 2, 3])\ncpu\n"
     ]
    }
   ],
   "source": [
    "# Tensor will be saved on memory(CPU) by default\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(x)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 2, 3], device='cuda:0')\ncuda:0\n"
     ]
    }
   ],
   "source": [
    "# `cuda(i)` can be used to copy an object to GPU, i means the index of GPU\n",
    "x = x.cuda(0)\n",
    "print(x)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3], device='cuda:0'), tensor([1, 2, 3], device='cuda:0'))"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Or specify the device directly by creation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x = torch.tensor([1, 2, 3], device=device)\n",
    "# or\n",
    "y = torch.tensor([1, 2, 3]).to(device)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 4, 9], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Tensor on GPU will be calculated on  GPU\n",
    "z = x ** 2\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "expected device cuda:0 and dtype Long but got device cpu and dtype Long",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-36552bee9515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tensors on different devices can not be calculated together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: expected device cuda:0 and dtype Long but got device cpu and dtype Long"
     ]
    }
   ],
   "source": [
    "# Tensors on different devices can not be calculated together\n",
    "z = y + x.cpu()"
   ]
  },
  {
   "source": [
    "## 5.3 Model on GPU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "# Model is on cpu by default\n",
    "net = nn.Linear(3, 1)\n",
    "list(net.parameters())[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# Use `cuda()` to transfer model to GPU\n",
    "net.cuda()\n",
    "list(net.parameters())[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.2200],\n",
       "        [0.1605]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "x = torch.rand(2,3).cuda()\n",
    "net(x)"
   ]
  }
 ]
}